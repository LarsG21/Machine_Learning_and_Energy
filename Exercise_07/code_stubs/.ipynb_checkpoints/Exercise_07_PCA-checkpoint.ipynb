{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Machine Learning & Energy WS 20/21\n",
    "# Exercise 7 - Part II: Principal Component Analysis\n",
    "\n",
    "In this notebook you will first implement the PCA algorithm and test it on a toy data set. Then you will apply it to a high dimensional real world data set of temperature measurements."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "source": [
    "## 1. Toy data\n",
    "#### a) Run the cell below to create and plot the toy data set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0,0,0])\n",
    "cov = np.array([[1.2, 0.2, 0.2],[0.2, 1.0, 0.2], [0.2, 0.2, 1.1]])\n",
    "X =  mvn.rvs(mean=mu, cov=cov, size=50, random_state=99)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2])\n",
    "ax.set_xlim((-4,4))\n",
    "ax.set_ylim((-4,4))\n",
    "ax.set_zlim((-4,4))\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "ax.set_zlabel(\"x3\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "#### b) Complete the code for the function ``transform()`` in the module ``pca``.\n",
    "The function uses the PCA algorithm to return the compressed data using ``n_components`` dimensions. You can use ``np.cov()`` to find the covariance matrix and ``np.linalg.eig()`` to obtain the eigenvalues and eigenvectors.\n",
    "Run the cell below to check your implementation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pca\n",
    "W,U,eig_vals = pca.transform(X, n_components=2)\n",
    "print(f\"W:\\n{W[0:3,:]}\\nexpected W:\\n[[ 0.04453867  1.93138331]\\n [-1.61079467 -0.30778838]\\n [-0.95451705  0.59762263]]\\n\")\n",
    "print(f\"U:\\n{U}\\nexpected U:\\n[[ 0.61191346  0.78523211 -0.09472302]\\n [ 0.57353539 -0.52300039 -0.63049802]\\n [ 0.54462747 -0.33148322  0.77038938]]\\n\")\n",
    "print(f\"eigenvalues: {eig_vals}\\nexpected eigenvalues: [2.0364426  0.76344597 0.55722208]\")"
   ]
  },
  {
   "source": [
    "#### c) Complete the code for the function ``backtransform()`` in the module ``pca``.\n",
    "The function backtransforms the data to the original space.\n",
    "Run the cell below to check your implementation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec = pca.backtransform(W,U)\n",
    "print(f\"X_rec:\\n{W[0:3,:]}\\nexpected X_rec:\\n[[ 0.04453867  1.93138331]\\n [-1.61079467 -0.30778838]\\n [-0.95451705  0.59762263]]\\n\")"
   ]
  },
  {
   "source": [
    "#### d) Run the cell below to plot the original data, the recovered data, and the projection to the lower dimensional plane. Interpret the two plots."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,8))\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "# plot data points\n",
    "ax.scatter(X_rec[:,0], X_rec[:,1], X_rec[:,2], label=\"recovered data\", alpha=1)\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2], label=\"orginal data\", alpha=1)\n",
    "# plot scaled eigenvectors\n",
    "ax.plot([0,U[0,0]*eig_vals[0]], [0,U[1,0]*eig_vals[0]], [0,U[2,0]*eig_vals[0]], color=\"red\", label=\"scaled eigenvectors\")\n",
    "ax.plot([0,U[0,1]*eig_vals[1]], [0,U[1,1]*eig_vals[1]], [0,U[2,1]*eig_vals[1]], color=\"red\")\n",
    "ax.plot([0,U[0,2]*eig_vals[2]], [0,U[1,2]*eig_vals[2]], [0,U[2,2]*eig_vals[2]], color=\"red\")\n",
    "# plot plane and projections\n",
    "xx,yy = np.meshgrid(np.linspace(-3,3,100),np.linspace(-3,3,100))\n",
    "zz = (-U[0,2]*xx - U[1,2]*yy)/U[2,2]\n",
    "ax.plot_wireframe(xx, yy, zz, alpha=0.2, color=\"black\")\n",
    "for i in range(len(X)):\n",
    "    ax.plot([X[i,0],X_rec[i,0]], [X[i,1],X_rec[i,1]], [X[i,2],X_rec[i,2]], color=\"black\", linestyle=\":\")\n",
    "ax.set_xlim((-4,4))\n",
    "ax.set_ylim((-4,4))\n",
    "ax.set_zlim((-4,4))\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "ax.set_zlabel(\"x3\")\n",
    "ax.view_init(5, -155)\n",
    "ax.legend()\n",
    "# plot 2D data\n",
    "ax = fig.add_subplot(122)\n",
    "ax.scatter(W[:,0],W[:,1])\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_title(\"2D data\")\n",
    "ax.arrow(0,0,eig_vals[0],0, width=0.03, head_width=0.1, color=\"red\", label=\"scaled eigenvectors\")\n",
    "ax.arrow(0,0,0,eig_vals[1], width=0.03, head_width=0.1, color=\"red\")\n",
    "ax.set_xlim((-4,4))\n",
    "ax.set_ylim((-4,4))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "#### e) Confirm that:\n",
    "- all three eigenvectors are orthogonal to each other.\n",
    "- using all three principal components gives you a data set with zero covaraince and variances equal to the eigenvalues."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "source": [
    "## 2. Temperature data revisited\n",
    "In this section you will work with hourly temperature data for 293 German weather stations for the year 2020. This data set is quite high dimensional and large.\n",
    "Your goal is to find a lower dimensional representation using PCA.\n",
    "#### a) Run the cell below to load the data and plot a sample from it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_pickle(\"data/stations.pkl\")\n",
    "temp = pd.read_pickle(\"data/temp.pkl\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9,6))\n",
    "i=2000\n",
    "BBox = ((5.911,15.007,55.116, 47.279))\n",
    "BBox = ((5.911,15.007, 47.26, 55.3))\n",
    "map_img=plt.imread(\"images/map3.png\")\n",
    "sc=ax.scatter(stations[\"longitude\"], stations[\"latitude\"], alpha= 1.0, c=temp.iloc[i,:], s=50)\n",
    "fig.colorbar(sc)\n",
    "ax.set_xlim(BBox[0],BBox[1])\n",
    "ax.set_ylim(BBox[2],BBox[3])\n",
    "ax.imshow(map_img, extent = BBox, origin=\"upper\")\n",
    "ax.set_title(f\"measured temperatures in Â°C on {temp.index[i]}\")\n",
    "ax.set_ylabel(\"latitude\")\n",
    "ax.set_xlabel(\"longitude\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "#### b) Apply PCA to the temperature data.\n",
    "To determine the number of components, we can look at the variance explained, i.e. the ratio $$\\frac{\\sum_{i=1}^{K}\\lambda_i}{\\sum_{i=1}^{D}\\lambda_i},$$\n",
    "where $\\lambda_i$ is the $i$th largest eigenvalue, $K$ is the number of principal components and $D$ is the dimensionality of the data.\n",
    "\n",
    "How many principle components do you need such that 95% of the variance in the data is explained?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center the data\n",
    "X_temp = temp.values-np.mean(temp.values,axis=0)\n",
    "\n",
    "# ------ add code here ------\n",
    "\n",
    "\n",
    "var_explained_temp = np.ones(293) # <-- change this\n",
    "# ---------------------------\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1,X_temp.shape[1]+1,1), var_explained_temp)\n",
    "plt.ylabel(\"variance explained\")\n",
    "plt.xlabel(\"number of PCs\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "source": [
    "#### c) Run the cell below.\n",
    "It's often interesting to look at the values of the eigenvectors.\n",
    "\n",
    "Recall that the mapping for a data point $x=[x_1,...,x_D]$ to the $j$th principal component is given by $w_j=x_1u_{1,j} + x_2u_{2,j} + ... + x_Du_{D,j}$.\n",
    "\n",
    "In the map below you see the values for each dimension (i.e. each station) for the first, second, and third eigenvector. What do you observe?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3, figsize=(24,10))\n",
    "_,U_temp,_=pca.transform(X_temp,3)\n",
    "for i,ax in enumerate(axs):\n",
    "    sc=ax.scatter(stations[\"longitude\"], stations[\"latitude\"], alpha= 1.0, c=U_temp[:,i], s=50)\n",
    "    fig.colorbar(sc, shrink=0.5, ax=ax)\n",
    "    ax.set_xlim(BBox[0],BBox[1])\n",
    "    ax.set_ylim(BBox[2],BBox[3])\n",
    "    ax.set_xlim(BBox[0],BBox[1])\n",
    "    ax.set_ylim(BBox[2],BBox[3])\n",
    "    ax.imshow(map_img, extent = BBox, origin=\"upper\")\n",
    "    ax.set_title(\"u\"+str(i+1))"
   ]
  },
  {
   "source": [
    "That's it :) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}